{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOl/FYjzuf+FvaGJFhNom6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royam0820/taskingai/blob/main/taskingai_creation_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TaskingAI - Python SDK - Creation of an Assistant"
      ],
      "metadata": {
        "id": "dqCD1m-RJpNA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXOFqswa4FN6"
      },
      "outputs": [],
      "source": [
        "!pip install taskingai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import taskingai\n",
        "import os\n"
      ],
      "metadata": {
        "id": "aNkNWMel40_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment setup"
      ],
      "metadata": {
        "id": "lNf9jgPEBOLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "# Set the environment variable to be the value stored in user secrets.\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"TASKINGAI_API_KEY\"] =  userdata.get('TASKINGAI_API_KEY')"
      ],
      "metadata": {
        "id": "epP__5La5Cyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: in Google Colab, we can use the Secrets store to store APIs so that they are not visible in your code.\n",
        "\n",
        "Other method, in Visual Studio for exemple, is to create a text file named `.env` that will store you secret api keys like so:\n",
        "\n",
        "OPENAI_API_KEY=sk-xxxxxxxxxxxx\n",
        "\n",
        "TASKINGAI_API_KEY=taxxxxxxxxxxx\n",
        "\n",
        "then you need to install this package:\n",
        "`pip install python-dotenv` and the in your code load the environment variables `load_dotenv()`"
      ],
      "metadata": {
        "id": "69jqPuzQJ--l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taskingai Initialisation"
      ],
      "metadata": {
        "id": "fPXDlMWFBRvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taskingai.init(api_key=os.environ[\"TASKINGAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "uIN4AGjY5KeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a collection"
      ],
      "metadata": {
        "id": "zNsT-z82BZrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection = taskingai.retrieval.create_collection(\n",
        "    name=\"amrCollection\",\n",
        "    embedding_model_id=\"TpZAZqW9\",    #Gpt4-small-embeddings\n",
        "    capacity=1000,\n",
        ")"
      ],
      "metadata": {
        "id": "H08s4nVG5bP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: A collection is part of a RAG system and therefore records that will be added need to be processed via embeddings, hence the reference to an `embedding_model` for the collection we are creating. Here the `embedding_model_id=\"TpZAZqW9\"` refers to a gpt4-small-embeddings,\n",
        "\n",
        "[API collection creation](https://docs.tasking.ai/api/#tag/Retrieval/manage_collections/create_collection)"
      ],
      "metadata": {
        "id": "8mnL5S3W_0uE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a record for the collection"
      ],
      "metadata": {
        "id": "6NgCIJddBfVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from taskingai.retrieval import Record, TokenTextSplitter"
      ],
      "metadata": {
        "id": "oWD6tmJg9_N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record: Record = taskingai.retrieval.create_record(\n",
        "    collection_id=collection.collection_id,\n",
        "    content=\"Machine learning is a subfield of artificial intelligence...\",\n",
        "    text_splitter=TokenTextSplitter(chunk_size=200, chunk_overlap=20),\n",
        "    metadata={\"file_name\": \"machine_learning.pdf\"},\n",
        "    type=\"text\"  # specify the appropriate content type\n",
        ")"
      ],
      "metadata": {
        "id": "ma2MI-oR-nv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: In the record creation example above, the `type` can be `\"text\"`, `\"file\"` or `\"web\"`;  the `metadata` is a dictionary. It can be set to empty `{} since we are using a `\"text\"` record.\n",
        "\n",
        "The `text_splitter` indicates how to split records into chunks. It cannot change after creation.\n",
        "\n",
        "[API record creation](https://docs.tasking.ai/api/#tag/Retrieval/manage_collections/create_record)"
      ],
      "metadata": {
        "id": "PeisHQz6_BCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating an Assistant"
      ],
      "metadata": {
        "id": "oBa3zEjABnvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from taskingai.assistant.assistant import AssistantRetrieval, AssistantRetrievalType\n",
        "from taskingai.assistant.memory import AssistantNaiveMemory\n",
        "\n",
        "assistant = taskingai.assistant.create_assistant(\n",
        "    model_id=\"TpQuiRBb\",\n",
        "    name=\"amrAssistant\",\n",
        "    retrievals=[\n",
        "        AssistantRetrieval(\n",
        "            type=AssistantRetrievalType.COLLECTION,\n",
        "            id=collection.collection_id,\n",
        "        )\n",
        "    ],\n",
        "    memory=AssistantNaiveMemory(),\n",
        ")"
      ],
      "metadata": {
        "id": "4BOktfx0BrfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB: when creating an assistant you will need the following minimal values:\n",
        "- a `model_id` here we are using the GPT4 model id.\n",
        "- a `name`\n",
        "- a `retrieval`, here we are using a collection defined above based on `\"text\"`\n",
        "- `memory`: three types\n",
        "    - `naive`: uses a straightforward approach to memory management, storing all messages in a chat session.\n",
        "    - `zero` : is ideal for applications where context isn't required. It treats each interaction as an independent instance.\n",
        "    - `Message Window` : s optimized for long conversational threads where maintaining recent context is crucial. It avoids token wastage by focusing on the most relevant parts of the conversation.\n",
        "\n",
        "[Memory documentation](https://docs.tasking.ai/docs/guide/product_modules/assistant/components/memory/)\n",
        "\n",
        "\n",
        "[API assistant creation](https://docs.tasking.ai/api/#tag/Assistant/manage_collections/delete_assistant)"
      ],
      "metadata": {
        "id": "_OmgbprBB8GX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Chat and a message"
      ],
      "metadata": {
        "id": "5tW4nJENGrmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the chat\n",
        "chat = taskingai.assistant.create_chat(\n",
        "    assistant_id=assistant.assistant_id,\n",
        ")\n",
        "\n",
        "# Creating the message\n",
        "message = taskingai.assistant.create_message(\n",
        "    assistant_id=assistant.assistant_id,\n",
        "    chat_id=chat.chat_id,\n",
        "    text=\"In which country is paris?\",\n",
        ")\n",
        "\n",
        "# Printing only the MessageContent\n",
        "print(message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQBs_T7cHcXV",
        "outputId": "4c219f90-4e63-4055-95bd-4db2804efa75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='In which country is paris?'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB:\n",
        "[API create chat](https://docs.tasking.ai/api/#tag/Assistant/manage_collections/delete_chat)"
      ],
      "metadata": {
        "id": "cRnGbBemITg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the response"
      ],
      "metadata": {
        "id": "EEHZ9ExOHp0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant_message = taskingai.assistant.generate_message(\n",
        "    assistant_id=assistant.assistant_id,\n",
        "    chat_id=chat.chat_id,\n",
        ")\n",
        "\n",
        "print(f\"Assistant: {assistant_message.content.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BC8ptRduGmte",
        "outputId": "09e2096a-4ce1-45b7-846c-0ebd8f5ed459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: Paris is in France.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NB:\n",
        "[API generate message](https://docs.tasking.ai/api/#tag/Assistant/manage_collections/generate_message)"
      ],
      "metadata": {
        "id": "_Vtu8sv-I574"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat continuation"
      ],
      "metadata": {
        "id": "UthWmj8YH7Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taskingai.assistant.create_message(\n",
        "    assistant_id=assistant.assistant_id,\n",
        "    chat_id=chat.chat_id,\n",
        "    text=\"What to eat there? give me bullets points\",\n",
        ")\n",
        "assistant_message = taskingai.assistant.generate_message(\n",
        "    assistant_id=assistant.assistant_id,\n",
        "    chat_id=chat.chat_id,\n",
        ")\n",
        "\n",
        "print(f\"Assistant: {assistant_message.content.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsvfDZQ2H9b5",
        "outputId": "b67ac4f9-8061-415b-e2b6-b8f09d2b398e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assistant: Absolutely, here are some 'must-try' culinary delights in Paris:\n",
            "\n",
            "- Croissants and baguettes\n",
            "- Escargot (snails)\n",
            "- Coq au vin (chicken in wine sauce)\n",
            "- Crêpes \n",
            "- French pastries like macaroons, éclairs and tarts\n",
            "- Assortment of French cheeses\n",
            "- Variety of French wines\n",
            "- French onion soup\n",
            "- Ratatouille (vegetable stew)\n",
            "- Beef Bourguignon (beef stew made with red wine)\n",
            "- Bouillabaisse (fish stew)\n",
            "- Foie gras\n",
            "- Tarte tatin (upside-down caramelized apple tart)\n",
            "- Quiche Lorraine (a savory pie with bacon, cheese and egg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note\n",
        " TaskingAI gives you the ability to switch models quickly in your stateful application. Which is quite nice and handy!"
      ],
      "metadata": {
        "id": "IuCrFtb9Lqlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ressources\n",
        "- [Video - TaskingAI Introduction](https://youtu.be/4A5uQoawETU)\n",
        "- [TaskingAI Documentation](https://docs.tasking.ai/docs/guide/introduction)\n",
        "- [TaskingAI APIs](https://docs.tasking.ai/api/)\n",
        "- [TaskingAI Integration](https://docs.tasking.ai/docs/integration/overview)\n",
        "- [TaskingAI Examples](https://www.tasking.ai/examples)\n",
        "- [TaskingAI Inference](https://docs.tasking.ai/docs/taskingai-inference/overview)\n",
        "- [TaskingAI - Github](https://github.com/TaskingAI/)\n",
        "- [Docker Hosting](https://docs.tasking.ai/docs/guide/self-hosting-with-docker)\n",
        "- [TaskingAI Forum](https://forum.tasking.ai/)"
      ],
      "metadata": {
        "id": "YoWX3y32JNZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XJ14SWhJVdd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}